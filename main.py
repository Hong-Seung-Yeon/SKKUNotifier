# main.py
import os
import json
from dotenv import load_dotenv
from crawler import scrape_notices
from notifier import send_email

load_dotenv()

SENDER_EMAIL = os.getenv("SENDER_EMAIL")
SENDER_PASSWORD = os.getenv("SENDER_PASSWORD")
RECIPIENT_EMAIL = os.getenv("RECIPIENT_EMAIL")

NOTIFIED_IDS_FILE = "notified_posts.json"

# ì´ì „ì— ì•Œë¦¼ ë³´ë‚¸ ê²Œì‹œê¸€ ID ë¶ˆëŸ¬ì˜¤ê¸°
if os.path.exists(NOTIFIED_IDS_FILE):
    with open(NOTIFIED_IDS_FILE, "r") as f:
        notified_ids = set(json.load(f))
else:
    notified_ids = set()

new_posts = {}

for site_name, base_url in [
    ("ì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼", "https://cse.skku.edu/cse/notice.do"),
    ("ì†Œí”„íŠ¸ì›¨ì–´ìœµí•©ëŒ€í•™", "https://sw.skku.edu/sw/notice.do")
]:
    print(f"ğŸŒ {site_name} ê³µì§€ ìˆ˜ì§‘ ì¤‘...")
    posts = scrape_notices(site_name, base_url, notified_ids)
    if posts:
        new_posts[site_name] = posts

if new_posts:
    print("ğŸ“¬ ìƒˆ ê²Œì‹œê¸€ ë°œê²¬! ì´ë©”ì¼ ì „ì†¡ ì‹œì‘...")
    send_email(new_posts, sender_email=SENDER_EMAIL, sender_password=SENDER_PASSWORD, recipient_email=RECIPIENT_EMAIL)

    # ìƒˆë¡œìš´ ID ì €ì¥
    all_ids = notified_ids.union({post['id'] for posts in new_posts.values() for post in posts})
    with open(NOTIFIED_IDS_FILE, "w") as f:
        json.dump(list(all_ids), f)
    print(f"âœ… {sum(len(posts) for posts in new_posts.values())}ê±´ì˜ ìƒˆ ê²Œì‹œê¸€ ì €ì¥ ì™„ë£Œ.")
else:
    print("ğŸ” ìƒˆë¡œìš´ ê²Œì‹œê¸€ì´ ì—†ìŠµë‹ˆë‹¤.")
